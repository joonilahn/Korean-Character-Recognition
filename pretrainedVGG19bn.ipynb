{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, glob, argparse\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from scipy.ndimage import imread\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HangulDataset(Dataset):\n",
    "    \"\"\"Hangul Handwritten dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, subroot='char_data', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.subroot = subroot\n",
    "        self.transform = transform\n",
    "        self.classlist = os.listdir(os.path.join(root_dir, self.subroot))\n",
    "        self.targets = []\n",
    "        self.filenames = []\n",
    "        self.targetdict = {}\n",
    "        for i, label in enumerate(self.classlist):\n",
    "            files = glob.glob(\n",
    "                        os.path.join(self.root_dir, self.subroot, label) + '/*')\n",
    "            self.filenames += files\n",
    "            self.targets += [i] * len(files)\n",
    "            self.targetdict[i] = int(label, 16)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.filenames[idx]\n",
    "        target = self.targets[idx]\n",
    "        sample = imread(img_name, mode='L')\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return (sample, target)\n",
    "    \n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (self.output_size, self.output_size),\n",
    "                               mode='reflect')\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        maxval = img.max()\n",
    "        blkidx = np.where(img > maxval*0.95)\n",
    "        img[blkidx] = 0\n",
    "        return img\n",
    "    \n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        return image\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        dims = sample.shape\n",
    "        if len(dims) == 2:\n",
    "            image = np.expand_dims(sample, 0)\n",
    "        else:\n",
    "            image = sample.transpose((2, 0, 1))\n",
    "        sampletensor = torch.from_numpy(image)\n",
    "        return sampletensor.type(torch.FloatTensor)\n",
    "    \n",
    "class ObjectCrop(object):\n",
    "    \"\"\"Detect centre of character and crop unnecessary background\"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "            \n",
    "    def __call__(self, sample):\n",
    "        h, w = sample.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        # Get centre of character\n",
    "        minval = sample.min()\n",
    "        threshold = 0.1\n",
    "        whiteidx = np.where(sample > minval*threshold)\n",
    "        h_centre = whiteidx[0].mean().astype(int)\n",
    "        w_centre = whiteidx[1].mean().astype(int)\n",
    "        centrepixel = (h_centre, w_centre)\n",
    "\n",
    "        h_start = h_centre - (new_h // 2)\n",
    "        h_end = h_start + new_h\n",
    "        w_start = w_centre - (new_w // 2)\n",
    "        w_end = w_start + new_w\n",
    "\n",
    "        if h_start < 0:   # If new index is less than 0\n",
    "            h_start = 0\n",
    "            h_end = new_h - 1\n",
    "        elif h_end > h:   # If new index is larger than original height\n",
    "            h_end = h\n",
    "            h_start = h - new_h\n",
    "        if w_start < 0:\n",
    "            w_start = 0\n",
    "            w_end = new_w - 1\n",
    "        elif w_end > w:\n",
    "            w_end = w\n",
    "            w_start = w - new_w\n",
    "            \n",
    "        image = sample[h_start:h_end,\n",
    "                      w_start:w_end]\n",
    "\n",
    "        return image\n",
    "    \n",
    "class Stablize(object):\n",
    "    \"\"\"Stablize pixel values of images.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        sample = -(sample / 255) + 1\n",
    "        return sample\n",
    "    \n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize images.\"\"\"\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __call__(self, sample):\n",
    "        return (sample - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hangul_dataset = HangulDataset('set 01', transform=Stablize())\n",
    "transformed_dataset = HangulDataset(root_dir='set 01',\n",
    "                                    transform=transforms.Compose([\n",
    "                                    Stablize(),\n",
    "#                                     Normalize(0.027, 0.09),\n",
    "                                    Rescale(256),\n",
    "                                    ObjectCrop(224),\n",
    "                                    ToTensor(),    \n",
    "                                    transforms.Lambda(lambda x: torch.cat([x, x, x], 0)),\n",
    "                                           ]))\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=100,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-847b13c4f10c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msamplemean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampleidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msamplemean\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhangul_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampleidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msamplemean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamplemean\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msamplemean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-fb26a019647f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/scipy/ndimage/io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, flatten, mode)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_have_pil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     raise ImportError(\"Could not import the Python Imaging Library (PIL)\"\n\u001b[1;32m     26\u001b[0m                       \u001b[0;34m\" required to load image files.  Please refer to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(name, flatten, mode)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \"\"\"\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2559\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_open_core\u001b[0;34m(fp, filename, prefix)\u001b[0m\n\u001b[1;32m   2547\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maccept\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m                     \u001b[0m_decompression_bomb_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fp, filename)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         except (IndexError,  # end of data\n\u001b[1;32m    104\u001b[0m                 \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# end of data (ord)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# and load the first frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m_seek\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFileDirectory_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_v2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;31m# extract relevant tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOMPRESSION_INFO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMPRESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_planar_configuration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPLANAR_CONFIGURATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/_collections_abc.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;34m'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_dispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_api\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tags_v2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_api\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, tag, value)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegacy_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m_setitem\u001b[0;34m(self, tag, value, legacy_api)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mbasetypes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTiffTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasetypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/TiffTags.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(tag)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTAGS_V2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTagInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unknown'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/PIL/TiffTags.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, value, name, type, length, enum)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unknown\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         return super(TagInfo, cls).__new__(\n\u001b[0m\u001b[1;32m     28\u001b[0m             cls, value, name, type, length, enum or {})\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_data = len(hangul_dataset)\n",
    "mean = 0\n",
    "for j in range(10):\n",
    "    sampleidx = list(range(num_data))\n",
    "    np.random.shuffle(sampleidx)\n",
    "    samplemean = 0\n",
    "    for i in sampleidx[:1000]:\n",
    "        samplemean += np.mean(hangul_dataset[sampleidx[i]][0])\n",
    "    samplemean = samplemean / 1000\n",
    "    mean += samplemean\n",
    "mean /= 10\n",
    "print('mean: {}'.format(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample std: 88.5860092324008\n"
     ]
    }
   ],
   "source": [
    "sums = 0\n",
    "for i in sampleidx[:1000]:\n",
    "    sums += (hangul_dataset[sampleidx[i]][0] - mean).sum()**2\n",
    "samplestd = np.sqrt(sums / (num_data-1))\n",
    "print('sample std: {}'.format(samplestd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD8CAYAAADzEfagAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c21ed09e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(hangul_dataset[100][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/Joonil/anaconda/envs/pytorch/lib/python3.6/site-packages/cv2.cpython-36m-darwin.so, 2): Library not loaded: @rpath/libtiff.5.dylib\n  Referenced from: /Users/Joonil/anaconda/envs/pytorch/lib/libopencv_imgcodecs.3.3.dylib\n  Reason: Incompatible library version: libopencv_imgcodecs.3.3.dylib requires version 9.0.0 or later, but libtiff.5.dylib provides version 8.0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-72fbbcfe2587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/Joonil/anaconda/envs/pytorch/lib/python3.6/site-packages/cv2.cpython-36m-darwin.so, 2): Library not loaded: @rpath/libtiff.5.dylib\n  Referenced from: /Users/Joonil/anaconda/envs/pytorch/lib/libopencv_imgcodecs.3.3.dylib\n  Reason: Incompatible library version: libopencv_imgcodecs.3.3.dylib requires version 9.0.0 or later, but libtiff.5.dylib provides version 8.0.0"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Joonil/anaconda/envs/pytorch/lib/libopencv_imgcodecs.3.3.dylib:\r\n",
      "\t@rpath/libopencv_imgcodecs.3.3.dylib (compatibility version 3.3.0, current version 3.3.1)\r\n",
      "\t@rpath/libopencv_imgproc.3.3.dylib (compatibility version 3.3.0, current version 3.3.1)\r\n",
      "\t@rpath/libz.1.dylib (compatibility version 1.0.0, current version 1.2.11)\r\n",
      "\t@rpath/libjpeg.9.dylib (compatibility version 12.0.0, current version 12.0.0)\r\n",
      "\t@rpath/libpng16.16.dylib (compatibility version 49.0.0, current version 49.0.0)\r\n",
      "\t@rpath/libtiff.5.dylib (compatibility version 9.0.0, current version 9.0.0)\r\n",
      "\t@rpath/libjasper.1.dylib (compatibility version 2.0.0, current version 2.0.0)\r\n",
      "\t@rpath/libopencv_core.3.3.dylib (compatibility version 3.3.0, current version 3.3.1)\r\n",
      "\t@rpath/libc++.1.dylib (compatibility version 1.0.0, current version 1.0.0)\r\n",
      "\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1197.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!otool -L /Users/Joonil/anaconda/envs/pytorch/lib/libopencv_imgcodecs.3.3.dylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.fastNlMeansDenoising()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c225303c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = int(np.random.rand(1)*len(transformed_dataset))\n",
    "plt.imshow(transformed_dataset[idx][0].numpy().transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor sizes at /Users/soumith/miniconda2/conda-bld/pytorch_1503975723910/work/torch/lib/TH/generic/THTensorMath.c:2709",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-b1640ff1f38b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batch from dataloader'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample_batched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batched\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     raise TypeError((\"batch must contain tensors, numbers, dicts or lists; found {}\"\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     raise TypeError((\"batch must contain tensors, numbers, dicts or lists; found {}\"\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(sequence, dim, out)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor sizes at /Users/soumith/miniconda2/conda-bld/pytorch_1503975723910/work/torch/lib/TH/generic/THTensorMath.c:2709"
     ]
    }
   ],
   "source": [
    "def show_batch(sample_batched):\n",
    "    \"\"\"Show images for a batch of samples.\"\"\"\n",
    "    batch_size = len(sample_batched)\n",
    "    im_size = sample_batched.size(2)\n",
    "\n",
    "    grid = utils.make_grid(sample_batched)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    plt.title('Batch from dataloader')\n",
    "\n",
    "for i_batch, (sample_batched, target_batched) in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched.size())\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        plt.figure()\n",
    "        show_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_model = models.vgg19_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create custom VGG19_bn\n",
    "num_classes = 2350\n",
    "class CustomVGG19bn(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomVGG19bn, self).__init__()\n",
    "        self.features = nn.Sequential(*list(pretrained_model.features.children()))\n",
    "        self.classifier = nn.Sequential(\n",
    "            *[list(pretrained_model.classifier.children())[i] for i in range(6)],\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 25088)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# load custom model\n",
    "model = CustomVGG19bn(num_classes=2350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for layer_idx, param in enumerate(model.classifier.parameters()):\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([4096, 25088]), torch.Size([4096]), torch.Size([4096, 4096]), torch.Size([4096]), torch.Size([2350, 4096]), torch.Size([2350])]\n"
     ]
    }
   ],
   "source": [
    "# unfrozen_weights = filter(lambda x: x.requires_grad, model.parameters())\n",
    "# print(list(map(lambda x: x.size(), unfrozen_weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs).float().cuda()\n",
    "                    labels = Variable(labels).long().cuda()\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs).float(), Variable(labels).long()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # print every 10 iterations\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print('Epoch: {0:}/{1:}, Iterations: {2:}/{3:}, Training loss: {4:6.2f}'.\n",
    "                     format(epoch, num_epochs, i, len(dataloaders[phase]), loss.data[0]))\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, test data split\n",
    "num_data = len(hangul_dataset.filenames)\n",
    "indices = list(range(num_data))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_size = 0.20\n",
    "test_size = 0.20\n",
    "test_split = int(np.floor(test_size * num_data))\n",
    "val_split = test_split + int(np.floor(val_size * num_data))\n",
    "num_train = num_data - val_split - test_split\n",
    "train_idx, val_idx, test_idx = indices[val_split:], indices[test_split:val_split] , indices[:test_split]\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 1\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    " # Define sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# Train, test dataset loader\n",
    "train_loader = DataLoader(transformed_dataset, \n",
    "                        batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "val_loader = DataLoader(transformed_dataset, \n",
    "                        batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "test_loader = DataLoader(transformed_dataset, \n",
    "                        batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "dataloaders = {'train':train_loader, 'val':val_loader, 'test':test_loader}\n",
    "\n",
    " # use gpu if cuda is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-277c9c8400cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=num_epochs)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-a296d4038eb2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py36",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
